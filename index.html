<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>MOA1</title>

  <!-- jsPsych CSS -->
  <link rel="stylesheet" href="https://unpkg.com/jspsych@7.3.4/css/jspsych.css" />

  <style>
    /* Layout & base */
    .jspsych-content-wrapper { display:flex; justify-content:center; }
    .jspsych-content { max-width:960px !important; margin:40px auto !important; }
    body { font-family: system-ui, sans-serif; background:#fafafa; line-height:1.6; }

    .center { text-align:center; }
    h2.center, h3.center { text-align:center; }

    ol, ul { text-align:left; margin-left:1.5em; }

    video { display:block; margin:0 auto; border-radius:10px; background:#000; }
    .grid { display:grid; grid-template-columns:1fr 1fr; gap:16px; align-items:start; }
    .cell { text-align:center; }
    .tag { font-weight:700; margin:6px 0 8px; }
    .cell video { cursor:pointer; }

    .jspsych-slider-container .jspsych-slider-labels {
      display:flex !important; justify-content:space-between !important; gap:0 !important;
      margin-top:10px !important; font-size:14px !important; line-height:1.2 !important;
    }
    .jspsych-slider-container .jspsych-slider-label { text-align:center !important; flex:0 0 auto !important; }

    video::-webkit-media-controls-timeline,
    video::-webkit-media-controls-current-time-display,
    video::-webkit-media-controls-time-remaining-display { display:none !important; }
    video::-moz-media-controls-seekbar { display:none !important; }
  </style>
</head>
<body></body>

<script type="module">
  /* ================================ Error surface ================================ */
  window.onerror = (m, s, l, c, e) => {
    document.body.innerHTML = "<pre style='white-space:pre-wrap'>" + m + "\n" + (e && e.stack || "") + "</pre>";
  };

  /* ================================= Imports ================================= */
  import { initJsPsych } from "https://esm.sh/jspsych";
  import jsPsychHtmlSliderResponse from "https://esm.sh/@jspsych/plugin-html-slider-response";
  import jsPsychHtmlButtonResponse from "https://esm.sh/@jspsych/plugin-html-button-response";
  import jsPsychSurveyText        from "https://esm.sh/@jspsych/plugin-survey-text";

/* =========================== Helpers & data upload =========================== */
function getParam(name){
  const m = new URLSearchParams(location.search).get(name);
  return m ? decodeURIComponent(m) : "";
}

const GS_WEBAPP_URL = "https://script.google.com/macros/s/AKfycbyc7DZuAv1G0pMtfHrMocTlWCgsDgg09Pun99RtUwyJTR0hDOZNdOnQvtIe4MK0EqSUng/exec";

// (Optional) trim heavy fields before upload to keep payload small
function compactRows(rows){
  return rows.map(r => {
    const {
      phase, scene, direction, moa, rt, response,
      correct_index, is_correct, choice_index, choice_letter,
      option_tags // keep small, informative arrays
    } = r;
    return {
      phase, scene, direction, moa, rt, response,
      correct_index, is_correct, choice_index, choice_letter,
      option_tags
    };
  });
}

const jsPsych = initJsPsych({
  on_finish: async () => {
    const raw = jsPsych.data.get().values();
    const payload = {
      timestamp: new Date().toISOString(),
      participant: getParam("pid") || "",
      userAgent: navigator.userAgent,
      // use compactRows(raw) if you want a smaller upload; or keep raw
      data: compactRows(raw)
    };

    try {
      await fetch(GS_WEBAPP_URL, {
        method: "POST",
        headers: { "Content-Type": "text/plain;charset=UTF-8" }, // simple request (no preflight)
        body: JSON.stringify(payload)
      });
      alert("Thanks! Your data was uploaded to Google Sheets.");
    } catch (e) {
      console.error(e);
      jsPsych.data.get().localSave("csv", "moa1_fallback.csv");
      alert("Upload failed — CSV downloaded locally instead.");
    }
  }
});

  /* ================================ UI utils ================================= */
  function lockRate(video, rate){
    const apply = () => { video.defaultPlaybackRate = rate; video.playbackRate = rate; };
    const end = performance.now() + 2000;
    (function tick(){ apply(); if (performance.now() < end) requestAnimationFrame(tick); })();
    ["play","ratechange","seeking","loadeddata","ended"].forEach(ev => video.addEventListener(ev, apply));
  }
  function screenTrial(html, btn = "Continue"){
    return { type: jsPsychHtmlButtonResponse, stimulus: `<div class="wrap">${html}</div>`, choices: [btn] };
  }
  function setupHoverGrid(videoIds, rates){
    const vids = videoIds.map(id => document.getElementById(id));
    const pauseAll = () => vids.forEach(v => { try { v.pause(); } catch(_){} });
    vids.forEach((v, i) => {
      const rate = rates[i] ?? 1.0;
      v.muted = true; v.playsInline = true;
      const prime = () => { try { v.load(); } catch(_){}; v.removeEventListener('mouseenter', prime); };
      v.addEventListener('mouseenter', prime, { once:true });
      v.addEventListener('mouseenter', () => {
        pauseAll(); if (rate !== 1.0) { lockRate(v, rate); } else { v.playbackRate = 1.0; }
        try { if (v.currentTime === 0) v.currentTime = 0.001; } catch(_){}
        v.play().catch(()=>{});
      });
      v.addEventListener('mouseleave', () => { try { v.pause(); v.currentTime = 0; } catch(_){} });
      v.addEventListener('touchstart', (e) => {
        e.preventDefault();
        const wasPlaying = !v.paused && !v.ended;
        pauseAll();
        if (!wasPlaying){
          if (rate !== 1.0) { lockRate(v, rate); } else { v.playbackRate = 1.0; }
          try { if (v.currentTime === 0) v.currentTime = 0.001; } catch(_){}
          v.play().catch(()=>{});
        } else { try { v.pause(); v.currentTime = 0; } catch(_){} }
      }, { passive:false });
    });
  }

  /* ================================ Builders ================================= */
  function viewClip(t){
    const html = `
      <div class="center">
        <p id="watchmsg">Click "Play" to watch the clip. "Continue" will appear after it ends.</p>
        <video id="mainvid" width="900" controls playsinline preload="metadata"
               controlslist="nodownload noplaybackrate noremoteplayback">
          <source src="${t.stimulus}" type="video/mp4">
        </video>
        <div id="btnbox"></div>
      </div>`;
    return {
      type: jsPsychHtmlButtonResponse, stimulus: html, choices: [],
      data: { phase: "view", ...t },
      on_load: () => {
        const v = document.getElementById("mainvid");
        const box = document.getElementById("btnbox");
        const msg = document.getElementById("watchmsg");
        let revealed = false;
        const showContinue = () => {
          if (revealed) return; revealed = true;
          msg.textContent = "You can continue.";
          const btn = document.createElement("button");
          btn.className = "jspsych-btn"; btn.textContent = "Continue →";
          btn.onclick = () => jsPsych.finishTrial({ phase: "view", ...t });
          box.appendChild(btn);
        };
        const firstPlay = () => { v.removeAttribute("controls"); v.addEventListener("pause", () => { if (!v.ended) v.play().catch(()=>{}); }); v.removeEventListener("play", firstPlay); };
        v.addEventListener("play", firstPlay);
        lockRate(v, 1.0);
        v.addEventListener("ended", showContinue, { once:true });
        v.addEventListener("contextmenu", e => e.preventDefault());
      }
    };
  }
  function prefSlider(t){
    return {
      type: jsPsychHtmlSliderResponse,
      stimulus: '<div class="center"><p><strong>How much did you like the clip you just watched?</strong></p></div>',
      min:0, max:4, step:1, slider_start:2, slider_width:700,
      labels:["0 (Not at all)","1","2 (Neutral)","3","4 (Very much)"],
      require_movement:true, data:{ phase:"preference", ...t }
    };
  }
  function simultaneitySlider(t){
    return {
      type: jsPsychHtmlSliderResponse,
      stimulus: '<div class="center"><p><strong>To what extent did the visual and auditory motion begin at the same time?</strong></p></div>',
      min:0, max:4, step:1, slider_start:2, slider_width:700,
      labels:["0 (Very far apart)","1","2 (Somewhat apart)","3","4 (Exactly the same time)"],
      require_movement:true, data:{ phase:"simultaneity_slider", ...t }
    };
  }
  function memoryTrial(t){
    const flip      = t.direction === "LtoR" ? "RtoL" : "LtoR";
    const correct   = { src: `videos/${t.scene}_${t.direction}_${t.moa}.mp4`, rate: 1.0, tag: "correct" };
    const wrongDir  = { src: `videos/${t.scene}_${flip}_${t.moa}.mp4`,        rate: 1.0, tag: "wrong_dir" };
    const wrongSpd  = { src: correct.src,                                      rate: 0.7, tag: "wrong_speed" };
    const bothWrong = { src: wrongDir.src,                                     rate: 0.7, tag: "both_wrong" };

    const opts = jsPsych.randomization.shuffle([correct, wrongDir, wrongSpd, bothWrong]);
    const correct_index = opts.findIndex(o => o.tag === "correct");
    const letters = ["A","B","C","D"];

    const gridHTML = `
      <div class="grid">
        ${opts.map((o,i)=>`
          <div class="cell">
            <div class="tag">${letters[i]}</div>
            <video id="opt${i}" loop playsinline preload="metadata" width="420">
              <source src="${o.src}" type="video/mp4">
            </video>
          </div>`).join("")}
      </div>
      <div class="center"><p>Hover (or tap) an option to play. Which clip matches the one you just watched (same direction & speed)?</p></div>`;

    return {
      type: jsPsychHtmlButtonResponse, stimulus: gridHTML, choices: letters,
      on_load: () => { const ids = opts.map((_,i)=>`opt${i}`); const rates = opts.map(o => o.rate); setupHoverGrid(ids, rates); },
      data: { phase:"memory", ...t, option_tags: opts.map(o=>o.tag), option_srcs: opts.map(o=>o.src), option_rates: opts.map(o=>o.rate), correct_index, is_correct:null },
      on_finish: (d) => {
        d.choice_index  = d.response;
        d.choice_letter = ["A","B","C","D"][d.response];
        d.chosen_tag    = d.option_tags[d.response];
        d.correct_tag   = d.option_tags[d.correct_index];
        d.is_correct    = (d.response === d.correct_index);
      }
    };
  }
  function memoryTrialPractice(t){
    const src = t.stimulus;
    const make = (tag, rate, flip) => ({ src, rate, tag, flip });
    const opts = jsPsych.randomization.shuffle([
      make("correct",1.0,false),
      make("wrong_speed",0.7,false),
      make("wrong_dir",1.0,true),
      make("both_wrong",0.7,true)
    ]);
    const letters = ["A","B","C","D"];
    const correct_index = opts.findIndex(o => o.tag === "correct");
    const gridHTML = `
      <div class="grid">
        ${opts.map((o,i)=>`
          <div class="cell">
            <div class="tag">${letters[i]}</div>
            <video id="opt${i}" loop playsinline preload="metadata" width="420" ${o.flip ? 'style="transform:scaleX(-1)"' : ''}>
              <source src="${o.src}" type="video/mp4">
            </video>
          </div>`).join("")}
      </div>
      <div class="center"><p>Hover (or tap) an option to play. Which clip matches the one you just watched (same direction & speed)?</p></div>`;
    return {
      type: jsPsychHtmlButtonResponse, stimulus: gridHTML, choices: letters,
      on_load: () => { const ids = opts.map((_,i)=>`opt${i}`); const rates = opts.map(o => o.rate); setupHoverGrid(ids, rates); },
      data: { phase:"memory_practice", ...t, correct_index, option_order: opts.map(o=>o.tag).join(","), is_correct:null },
      on_finish: (d) => {
        d.choice_index = d.response;
        const tags = d.option_order.split(",");
        d.chosen_tag  = tags[d.response];
        d.correct_tag = tags[d.correct_index];
        d.is_correct  = (d.response === d.correct_index);
      }
    };
  }

  /* ============================== Experiment consts ============================== */
  const scenes     = ["car","dog","horse","penguin","plane","roomba"];
  const directions = ["LtoR","RtoL"];
  const moas       = ["0s","1s","3s"];

  /* ================================ Consent ================================= */
  let CONSENT_GIVEN = false; // (you said you’ll save regardless; we still record it)
const CONSENT_HTML = `
  <div style="max-width:900px;margin:0 auto;text-align:left;font-size:16px;line-height:1.5">
    <h2 class="center">Informed Consent Information for Research Participation</h2>

    <p><strong>Primary Investigator:</strong> Sijia (Estelle) Song<br>
       <strong>Department:</strong> Department of Psychology, University at Albany<br>
       <strong>Term:</strong> Fall 2025<br>
       <strong>Study Title:</strong> “Preferences and Memory for Short Animated Clips (Study 1)”</p>

    <p><strong>PURPOSE:</strong> This study examines people’s preferences for and memory of short animated clips.</p>

    <p><strong>PROCEDURES:</strong> In this study, you’ll watch a set of short animated videos. After each video, you’ll:
      (1) tell us how much you liked it,
      (2) tell us if the picture and the sound seemed to start together,
      (3) pick the right answer to a short memory question.
      At the end, you’ll answer a few quick questions about yourself. The study will take about 30 minutes.</p>

    <p><strong>BENEFITS:</strong> Although you may not directly benefit from your participation, society may ultimately benefit from the knowledge obtained from this research.
      It is anticipated that this study will provide meaningful information about people’s preferences for and memory of short animated clips.</p>

    <p><strong>RISKS:</strong> We do not anticipate more than minimal risk in your participation. Your participation in the study is confidential, and all data will be kept anonymous
      (answers you enter into the computer will not be associated with your name or any other personal identifiers). You can choose not to answer any questions that you find
      uncomfortable, and if you feel uncomfortable during the study for any reason, you can discontinue participation at any time without penalty.</p>

    <p><strong>PARTICIPATION:</strong> Your participation in this study is voluntary. Even after you agree to participate in the research or sign the informed consent document,
      you may decide to leave the study at any time without penalty or loss of benefits to which you may otherwise have been entitled. You can stop participating at any time
      during the study by notifying the researcher and may also refrain from answering any questions that you would feel uncomfortable answering. You also may choose to
      withhold any of your responses from inclusion in the study.</p>

    <p><strong>COMPENSATION:</strong> All students who choose to participate in this study will be awarded <strong>0.5 credit</strong> toward fulfillment of the research
      requirement in APSY 101 (Introductory Psychology).</p>

    <p><strong>CONFIDENTIALITY:</strong> All responses are anonymous. None of the data collected on the computer will contain information that could be used to identify you.
      Data will be maintained for a minimum of 3 and a maximum of 5 years, at which point it will be destroyed. Study results will be reported for the group only and will not
      refer to individuals. Results may be reported in the context of scientific journals, professional presentations, and other reputable venues. All information obtained in this
      study is strictly confidential unless disclosure is required by law. In addition, the Institutional Review Board, and University or government officials responsible for
      monitoring this study may inspect these records.</p>

    <p><strong>Contacts:</strong> You may contact the researcher, Sijia (Estelle) Song, at
      <a href="mailto:ssong@albany.edu">ssong@albany.edu</a> or the researcher’s faculty advisor, Dr. Ronald Friedman (UAlbany Professor of Psychology), at
      <a href="mailto:rfriedman@albany.edu">rfriedman@albany.edu</a> if you would like any additional information about this study or its results.</p>

    <p><strong>YOUR RIGHTS AS A PARTICIPANT:</strong></p>
    <p>Research at the University at Albany involving human participants is carried out under the oversight of the Institutional Review Board (IRB).
      This research has been reviewed and approved by the IRB. If you have any questions concerning your rights as a research subject or if you wish to report any concerns about
      the study, you may contact the University at Albany Office of Regulatory and Research Compliance at 1400 Washington Ave, Albany, NY (MSC 100E) 12222,
      1-866-857-5459, or <a href="mailto:rco@albany.edu">rco@albany.edu</a>.</p>

    <hr>
    <p><em>I have read, or been informed of, the information about this study. I hereby consent to participate in the study.</em></p>
  </div>
`;
  const consentTrial = {
    type: jsPsychHtmlButtonResponse,
    stimulus: CONSENT_HTML,
    choices: ["Yes, I consent", "No, I do not consent"],
    on_finish: (data) => {
      data.phase = "consent";
      data.consent_choice = data.response === 0 ? "yes" : "no";
      CONSENT_GIVEN = (data.response === 0);
    }
  };

  /* ================================ Intro screens ================================ */
  const introScreens = [
    screenTrial(`
      <h2 class="center">Welcome to the study!</h2>
      <p style="text-align:left;">
        In this study, you will watch 36 short animated videos showing objects moving across the screen.
        The sound will also move between your left and right headphones as the object moves.
      </p>
      <p style="text-align:left;">
        To clearly hear the sound moving from side to side,
        <strong>please make sure you are wearing headphones in a quiet environment before continuing.</strong>
      </p>
      <p style="text-align:left;">You may need to scroll down to view the entire page.</p>
    `, "Next"),
    screenTrial(`
      <h3 class="center">What you'll do after each video</h3>
      <ol>
        <li><strong>Preference rating</strong> – “How much did you like the clip you just watched?”</li>
        <li><strong>Timing judgment</strong> – “To what extent did the visual and auditory motion begin at the same time?”<br>
          <small>This means: did the movement you <em>saw</em> and the movement you <em>heard</em> seem to start together, or did one begin slightly earlier?</small>
        </li>
        <li><strong>Memory test</strong> – Choose which of four options matches the clip you just watched. Options may differ in <em>direction</em> and/or <em>speed</em>.</li>
      </ol>
      <p>After all 36 trials, you’ll answer a few brief demographic questions.</p>
    `, "Next"),
    screenTrial(`
      <h3 class="center">Using the sliders</h3>
      <p>For the preference and timing ratings, you will use a slider from <strong>0 to 4</strong>.</p>
      <ul>
        <li>Move the slider to the number that best matches your judgment.</li>
        <li>If you want to select <strong>2 (Neutral)</strong>, click directly on the scale at 2.</li>
      </ul>
      <p>Let's start with a practice trial to learn the task.</p>
    `, "Begin practice")
  ];

  /* =============================== Practice timeline =============================== */
  const practiceTrials = [
    { scene: "practice1", direction: "LtoR", moa: "demo", stimulus: "videos/practice1_LtoR_demo.mp4" }
  ];
  const practiceTimeline = [
    viewClip(practiceTrials[0]),
    prefSlider(practiceTrials[0]),
    simultaneitySlider(practiceTrials[0]),
    memoryTrialPractice(practiceTrials[0])
  ];
  const practiceCompleteScreen = screenTrial(`
    <div class="center">
      <h3>Practice complete!</h3>
      <p>The main experiment will now begin.</p>
    </div>`, "Start main task");

  /* ================================== Main trials ================================== */
  const allTrials = [];
  scenes.forEach(scene=>{
    directions.forEach(dir=>{
      moas.forEach(moa=>{
        allTrials.push({ scene, direction: dir, moa, stimulus: `videos/${scene}_${dir}_${moa}.mp4` });
      });
    });
  });
function shuffleWithSceneGap(trials, maxTries = 5000){
  for (let tries = 0; tries < maxTries; tries++){
    const s = jsPsych.randomization.shuffle(trials);
    let ok = true;
    for (let i = 1; i < s.length; i++){
      if (s[i-1].scene === s[i].scene){ ok = false; break; }
    }
    if (ok) return s;
  }

  // Greedy fallback: interleave by scene
  const buckets = {};
  trials.forEach(t => { (buckets[t.scene] = buckets[t.scene] || []).push(t); });
  Object.values(buckets).forEach(arr => jsPsych.randomization.shuffle(arr));

  const sceneKeys = Object.keys(buckets);
  const result = [];
  let lastScene = null;

  while (result.length < trials.length){
    const choices = sceneKeys.filter(k => k !== lastScene && buckets[k].length > 0);
    const pickScene = choices.length
      ? choices[Math.floor(Math.random() * choices.length)]
      : sceneKeys.find(k => buckets[k].length > 0);
    result.push(buckets[pickScene].pop());
    lastScene = pickScene;
  }
  return result;
}

const constrained = shuffleWithSceneGap(allTrials);

const mainTimeline = [];
constrained.forEach(T => {
  mainTimeline.push(viewClip(T));
  mainTimeline.push(prefSlider(T));
  mainTimeline.push(simultaneitySlider(T));
  mainTimeline.push(memoryTrial(T));
});
  /* ============================ Final questions & Debrief ============================ */
  function oneTextQuestion({name, prompt, placeholder = "", required = true, button = "Continue"}) {
    return {
      type: jsPsychSurveyText,
      preamble: `<div class="center"><h2>Final Questions</h2></div>`,
      questions: [{ prompt: `<p style="font-weight:600;margin:0 0 8px">${prompt}</p>`, name, required, placeholder }],
      button_label: button,
      on_load: () => {
        const style = document.createElement("style");
        style.textContent = `
          .jspsych-survey-text .jspsych-survey-text-preamble { text-align:center; }
          .jspsych-survey-text-question { max-width:720px; margin:0 auto 18px; text-align:left; }
          .jspsych-survey-text-question input { width:100%; padding:10px; border-radius:8px; border:1px solid #ddd; font-size:16px; }
          .jspsych-btn { padding:10px 18px; border-radius:8px; }
        `;
        document.head.appendChild(style);
      }
    };
  }
  const q_age    = oneTextQuestion({ name:"age",            prompt:"1) Please enter your age.",            placeholder:"e.g., 26; 52" });
  const q_gender = oneTextQuestion({ name:"gender",         prompt:"2) Please enter your gender.",         placeholder:"e.g., woman / man / nonbinary / prefer to self-describe" });
  const q_race   = oneTextQuestion({ name:"race_ethnicity", prompt:"3) Please enter your race/ethnicity.", placeholder:"e.g., Asian; White; Black; Hispanic/Latino; Multiracial; …" });
  const q_hearing= oneTextQuestion({ name:"hearing",        prompt:"4) Do you have normal hearing?",       placeholder:"Yes / No / Unsure" });

const final_debrief = {
  type: jsPsychHtmlButtonResponse,
  stimulus: `
    <div style="max-width:820px;margin:0 auto;line-height:1.5;text-align:left;">
      <h2 class="center">Thank you for participating in this study!</h2>

      <p><strong>What was this study about?</strong><br>
      We’re studying how people remember short videos and how much they like them—especially when what you see and what you hear don’t line up perfectly. 
      In everyday life, sights and sounds usually start together (for example, you see a car move and hear it at the same time). 
      In our study, we sometimes made the sound’s movement start a little after the picture’s movement. 
      This timing gap is called motion onset asynchrony (MOA).</p>

      <p><strong>What did we test?</strong><br>
      We used three setups: no delay, a small delay, and a larger delay. 
      Our main idea is that a moderate delay might be “just right”—interesting enough to grab attention and help memory and liking, 
      but not so off that it feels distracting. We’ll also test whether liking helps explain memory—in other words, 
      whether clips you like more are also easier to remember when timing is a little off.</p>

      <p><strong>Why does this matter?</strong><br>
      Extended reality (XR) is used in training, education, games, and entertainment. Designers want experiences that people enjoy and also remember. 
      Those goals don’t always match: very immersive experiences can feel amazing yet sometimes make it harder to remember details, 
      while simpler setups can aid memory but feel less engaging. Our results can help find a better balance.</p>

      <p>If you would like to discuss the study further or are curious about this research, 
      please feel free to contact the researcher, <a href="mailto:ssong@albany.edu">Estelle Song</a>, 
      or the faculty advisor, <a href="mailto:rfriedman@albany.edu">Dr. Ronald Friedman</a>. 
      You may also contact either researcher if you would like your data withdrawn from the study. 
      If you choose to do so, you will still receive full credit for participation and will not be penalized in any way.</p>

      <p>If you experienced any discomfort during this study, or wish to discuss any other concerns, 
      you may contact the University Counseling Center at (518) 442-5800.</p>

      <p>Because this research is potentially important, we kindly ask that you please do not discuss the study with others before they participate. 
      Prior knowledge could affect their natural responses.</p>

      <p class="center"><strong>Thank you very much for your assistance with this project!</strong></p>
    </div>`,
  choices: ["Finish"]
};

  /* ===================================== Run ===================================== */
  jsPsych.run([
    consentTrial,           // consent first
    ...introScreens,
    ...practiceTimeline,
    practiceCompleteScreen,
    ...mainTimeline,
    q_age, q_gender, q_race, q_hearing,
    final_debrief
  ]);
</script>
</html>



