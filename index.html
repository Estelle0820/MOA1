<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>MOA1</title>

  <!-- jsPsych CSS -->
  <link rel="stylesheet" href="https://unpkg.com/jspsych@7.3.4/css/jspsych.css" />

  <style>
    /* Layout & base */
    .jspsych-content-wrapper { display:flex; justify-content:center; }
    .jspsych-content { max-width:960px !important; margin:40px auto !important; }
    body { font-family: system-ui, sans-serif; background:#fafafa; line-height:1.6; }

    .center { text-align:center; }
    h2.center, h3.center { text-align:center; }

    ol, ul { text-align:left; margin-left:1.5em; }

    video { display:block; margin:0 auto; border-radius:10px; background:#000; }
    .grid { display:grid; grid-template-columns:1fr 1fr; gap:16px; align-items:start; }
    .cell { text-align:center; }
    .tag { font-weight:700; margin:6px 0 8px; }
    .cell video { cursor:pointer; }

    .jspsych-slider-container .jspsych-slider-labels {
      display:flex !important; justify-content:space-between !important; gap:0 !important;
      margin-top:10px !important; font-size:14px !important; line-height:1.2 !important;
    }
    .jspsych-slider-container .jspsych-slider-label { text-align:center !important; flex:0 0 auto !important; }

    video::-webkit-media-controls-timeline,
    video::-webkit-media-controls-current-time-display,
    video::-webkit-media-controls-time-remaining-display { display:none !important; }
    video::-moz-media-controls-seekbar { display:none !important; }
  </style>
</head>
<body></body>

<script type="module">
  /* ================================ Error surface ================================ */
  window.onerror = (m, s, l, c, e) => {
    document.body.innerHTML = "<pre style='white-space:pre-wrap'>" + m + "\n" + (e && e.stack || "") + "</pre>";
  };

  /* ================================= Imports ================================= */
  import { initJsPsych } from "https://esm.sh/jspsych";
  import jsPsychHtmlSliderResponse from "https://esm.sh/@jspsych/plugin-html-slider-response";
  import jsPsychHtmlButtonResponse from "https://esm.sh/@jspsych/plugin-html-button-response";
  import jsPsychSurveyText        from "https://esm.sh/@jspsych/plugin-survey-text";

/* =========================== Helpers & data upload =========================== */
function getParam(name){
  const m = new URLSearchParams(location.search).get(name);
  return m ? decodeURIComponent(m) : "";
}

const GS_WEBAPP_URL = "https://script.google.com/macros/s/AKfycbyc7DZuAv1G0pMtfHrMocTlWCgsDgg09Pun99RtUwyJTR0hDOZNdOnQvtIe4MK0EqSUng/exec";

// (Optional) trim heavy fields before upload to keep payload small
function compactRows(rows){
  return rows.map(r => {
    const {
      phase, scene, direction, moa, rt, response,
      correct_index, is_correct, choice_index, choice_letter,
      option_tags // keep small, informative arrays
    } = r;
    return {
      phase, scene, direction, moa, rt, response,
      correct_index, is_correct, choice_index, choice_letter,
      option_tags
    };
  });
}

const jsPsych = initJsPsych({
  on_finish: async () => {
    const raw = jsPsych.data.get().values();
    const payload = {
      timestamp: new Date().toISOString(),
      participant: getParam("pid") || "",
      userAgent: navigator.userAgent,
      // use compactRows(raw) if you want a smaller upload; or keep raw
      data: compactRows(raw)
    };

    try {
      await fetch(GS_WEBAPP_URL, {
        method: "POST",
        headers: { "Content-Type": "text/plain;charset=UTF-8" }, // simple request (no preflight)
        body: JSON.stringify(payload)
      });
      alert("Thanks! Your data was uploaded to Google Sheets.");
    } catch (e) {
      console.error(e);
      jsPsych.data.get().localSave("csv", "moa1_fallback.csv");
      alert("Upload failed — CSV downloaded locally instead.");
    }
  }
});

  /* ================================ UI utils ================================= */
  function lockRate(video, rate){
    const apply = () => { video.defaultPlaybackRate = rate; video.playbackRate = rate; };
    const end = performance.now() + 2000;
    (function tick(){ apply(); if (performance.now() < end) requestAnimationFrame(tick); })();
    ["play","ratechange","seeking","loadeddata","ended"].forEach(ev => video.addEventListener(ev, apply));
  }
  function screenTrial(html, btn = "Continue"){
    return { type: jsPsychHtmlButtonResponse, stimulus: `<div class="wrap">${html}</div>`, choices: [btn] };
  }
  function setupHoverGrid(videoIds, rates){
    const vids = videoIds.map(id => document.getElementById(id));
    const pauseAll = () => vids.forEach(v => { try { v.pause(); } catch(_){} });
    vids.forEach((v, i) => {
      const rate = rates[i] ?? 1.0;
      v.muted = true; v.playsInline = true;
      const prime = () => { try { v.load(); } catch(_){}; v.removeEventListener('mouseenter', prime); };
      v.addEventListener('mouseenter', prime, { once:true });
      v.addEventListener('mouseenter', () => {
        pauseAll(); if (rate !== 1.0) { lockRate(v, rate); } else { v.playbackRate = 1.0; }
        try { if (v.currentTime === 0) v.currentTime = 0.001; } catch(_){}
        v.play().catch(()=>{});
      });
      v.addEventListener('mouseleave', () => { try { v.pause(); v.currentTime = 0; } catch(_){} });
      v.addEventListener('touchstart', (e) => {
        e.preventDefault();
        const wasPlaying = !v.paused && !v.ended;
        pauseAll();
        if (!wasPlaying){
          if (rate !== 1.0) { lockRate(v, rate); } else { v.playbackRate = 1.0; }
          try { if (v.currentTime === 0) v.currentTime = 0.001; } catch(_){}
          v.play().catch(()=>{});
        } else { try { v.pause(); v.currentTime = 0; } catch(_){} }
      }, { passive:false });
    });
  }

  /* ================================ Builders ================================= */
  function viewClip(t){
    const html = `
      <div class="center">
        <p id="watchmsg">Click "Play" to watch the clip. "Continue" will appear after it ends.</p>
        <video id="mainvid" width="900" controls playsinline preload="metadata"
               controlslist="nodownload noplaybackrate noremoteplayback">
          <source src="${t.stimulus}" type="video/mp4">
        </video>
        <div id="btnbox"></div>
      </div>`;
    return {
      type: jsPsychHtmlButtonResponse, stimulus: html, choices: [],
      data: { phase: "view", ...t },
      on_load: () => {
        const v = document.getElementById("mainvid");
        const box = document.getElementById("btnbox");
        const msg = document.getElementById("watchmsg");
        let revealed = false;
        const showContinue = () => {
          if (revealed) return; revealed = true;
          msg.textContent = "You can continue.";
          const btn = document.createElement("button");
          btn.className = "jspsych-btn"; btn.textContent = "Continue →";
          btn.onclick = () => jsPsych.finishTrial({ phase: "view", ...t });
          box.appendChild(btn);
        };
        const firstPlay = () => { v.removeAttribute("controls"); v.addEventListener("pause", () => { if (!v.ended) v.play().catch(()=>{}); }); v.removeEventListener("play", firstPlay); };
        v.addEventListener("play", firstPlay);
        lockRate(v, 1.0);
        v.addEventListener("ended", showContinue, { once:true });
        v.addEventListener("contextmenu", e => e.preventDefault());
      }
    };
  }
  function prefSlider(t){
    return {
      type: jsPsychHtmlSliderResponse,
      stimulus: '<div class="center"><p><strong>How much did you like the clip you just watched?</strong></p></div>',
      min:0, max:4, step:1, slider_start:2, slider_width:700,
      labels:["0 (Not at all)","1","2 (Neutral)","3","4 (Very much)"],
      require_movement:true, data:{ phase:"preference", ...t }
    };
  }
  function simultaneitySlider(t){
    return {
      type: jsPsychHtmlSliderResponse,
      stimulus: '<div class="center"><p><strong>To what extent did the visual and auditory motion begin at the same time?</strong></p></div>',
      min:0, max:4, step:1, slider_start:2, slider_width:700,
      labels:["0 (Very far apart)","1","2 (Somewhat apart)","3","4 (Exactly the same time)"],
      require_movement:true, data:{ phase:"simultaneity_slider", ...t }
    };
  }
  function memoryTrial(t){
    const flip      = t.direction === "LtoR" ? "RtoL" : "LtoR";
    const correct   = { src: `videos/${t.scene}_${t.direction}_${t.moa}.mp4`, rate: 1.0, tag: "correct" };
    const wrongDir  = { src: `videos/${t.scene}_${flip}_${t.moa}.mp4`,        rate: 1.0, tag: "wrong_dir" };
    const wrongSpd  = { src: correct.src,                                      rate: 0.7, tag: "wrong_speed" };
    const bothWrong = { src: wrongDir.src,                                     rate: 0.7, tag: "both_wrong" };

    const opts = jsPsych.randomization.shuffle([correct, wrongDir, wrongSpd, bothWrong]);
    const correct_index = opts.findIndex(o => o.tag === "correct");
    const letters = ["A","B","C","D"];

    const gridHTML = `
      <div class="grid">
        ${opts.map((o,i)=>`
          <div class="cell">
            <div class="tag">${letters[i]}</div>
            <video id="opt${i}" loop playsinline preload="metadata" width="420">
              <source src="${o.src}" type="video/mp4">
            </video>
          </div>`).join("")}
      </div>
      <div class="center"><p>Hover (or tap) an option to play. Which clip matches the one you just watched (same direction & speed)?</p></div>`;

    return {
      type: jsPsychHtmlButtonResponse, stimulus: gridHTML, choices: letters,
      on_load: () => { const ids = opts.map((_,i)=>`opt${i}`); const rates = opts.map(o => o.rate); setupHoverGrid(ids, rates); },
      data: { phase:"memory", ...t, option_tags: opts.map(o=>o.tag), option_srcs: opts.map(o=>o.src), option_rates: opts.map(o=>o.rate), correct_index, is_correct:null },
      on_finish: (d) => {
        d.choice_index  = d.response;
        d.choice_letter = ["A","B","C","D"][d.response];
        d.chosen_tag    = d.option_tags[d.response];
        d.correct_tag   = d.option_tags[d.correct_index];
        d.is_correct    = (d.response === d.correct_index);
      }
    };
  }
  function memoryTrialPractice(t){
    const src = t.stimulus;
    const make = (tag, rate, flip) => ({ src, rate, tag, flip });
    const opts = jsPsych.randomization.shuffle([
      make("correct",1.0,false),
      make("wrong_speed",0.7,false),
      make("wrong_dir",1.0,true),
      make("both_wrong",0.7,true)
    ]);
    const letters = ["A","B","C","D"];
    const correct_index = opts.findIndex(o => o.tag === "correct");
    const gridHTML = `
      <div class="grid">
        ${opts.map((o,i)=>`
          <div class="cell">
            <div class="tag">${letters[i]}</div>
            <video id="opt${i}" loop playsinline preload="metadata" width="420" ${o.flip ? 'style="transform:scaleX(-1)"' : ''}>
              <source src="${o.src}" type="video/mp4">
            </video>
          </div>`).join("")}
      </div>
      <div class="center"><p>Hover (or tap) an option to play. Which clip matches the one you just watched (same direction & speed)?</p></div>`;
    return {
      type: jsPsychHtmlButtonResponse, stimulus: gridHTML, choices: letters,
      on_load: () => { const ids = opts.map((_,i)=>`opt${i}`); const rates = opts.map(o => o.rate); setupHoverGrid(ids, rates); },
      data: { phase:"memory_practice", ...t, correct_index, option_order: opts.map(o=>o.tag).join(","), is_correct:null },
      on_finish: (d) => {
        d.choice_index = d.response;
        const tags = d.option_order.split(",");
        d.chosen_tag  = tags[d.response];
        d.correct_tag = tags[d.correct_index];
        d.is_correct  = (d.response === d.correct_index);
      }
    };
  }

  /* ============================== Experiment consts ============================== */
  const scenes     = ["car","dog","horse","penguin","plane","roomba"];
  const directions = ["LtoR","RtoL"];
  const moas       = ["0s","1s","3s"];

/* ================================ Consent ================================= */
let CONSENT_GIVEN = false; // will still record consent
const CONSENT_HTML = `
  <div style="max-width:900px;margin:0 auto;text-align:left;font-size:16px;line-height:1.5">
    <h2 class="center">University at Albany, SUNY</h2>
    <h3 class="center">Informed Consent Information for Research Participation</h3>

    <p><strong>Study Title:</strong> Preferences and Memory for Short Animated Clips (Study 1)<br>
       <strong>Principal Investigator:</strong> Sijia (Estelle) Song, M.A., Department of Psychology, University at Albany<br>
       <strong>Faculty Advisor:</strong> Dr. Ronald Friedman, Professor of Psychology, University at Albany<br>
       <strong>Study Sponsor:</strong> This study is not externally sponsored.</p>

    <h4>Why are you doing this study?</h4>
    <p>You are being asked to participate in a research study about people’s preferences for and memory of short animated clips.
    The purpose of this study is to better understand how people respond to audiovisual information, including how much they enjoy short animated clips and how well they remember details from them.</p>

    <h4>Why am I eligible to participate in this study?</h4>
    <p>You must be at least 18 years old and have normal or corrected-to-normal hearing. Individuals who have previously participated or enrolled in a related study titled 
    "Preferences and Memory for Short Animated Clips (Study 2)" will also be automatically excluded from enrolling in the proposed study via Sona.</p>

    <h4>What will I do if I choose to be in this study?</h4>
    <p>If you choose to participate, you will:</p>
    <ol>
      <li>Watch a set of short animated videos.</li>
      <li>After each video, answer three questions:
        <ul>
          <li>How much you liked the video.</li>
          <li>Whether the picture and sound seemed to start together.</li>
          <li>A short memory question about the video.</li>
        </ul>
      </li>
      <li>At the end, you will answer a few quick demographic questions about yourself (e.g., age, gender, hearing status).</li>
    </ol>
    <p>Participation will take place entirely online in a single session and will take approximately 30 minutes.</p>

    <h4>Are there any costs I should be aware of?</h4>
    <p>There are no costs associated with participating in this study other than your time and internet usage.</p>

    <h4>What are the possible risks or discomforts?</h4>
    <p>We do not anticipate more than minimal risk from your participation.</p>
    <ul>
      <li>You may feel some discomfort if you find certain questions uninteresting or repetitive.</li>
      <li>As with all online research, there is a small risk of breach of confidentiality. We will take steps to minimize this risk, as described below.</li>
    </ul>
    <p>This study will not involve any audio or video recording of you.</p>

    <h4>What are the possible benefits for me or others?</h4>
    <p>You may not directly benefit from participating in this study. However, the knowledge gained may help researchers better understand how people experience and remember audiovisual media.</p>

    <h4>Will I receive compensation for my participation?</h4>
    <p>Yes. Students who participate will receive <strong>0.5 research credit</strong> toward the APSY 101 (Introductory Psychology) course requirement.</p>

    <h4>How will you protect the information you collect about me, and how will that information be shared?</h4>
    <p>Your participation is confidential. No identifying information (such as your name or email address) will be collected.</p>
    <p>All data will be stored securely in University at Albany OneDrive, accessible only to the research team. Data will be retained for a minimum of three (3) years and a maximum of five (5) years, after which it will be permanently destroyed.</p>
    <p>Study results will be reported in aggregate (group-level) form in academic publications and presentations. Individual responses will not be linked to your identity.</p>

    <h4>Will my data be used in future research?</h4>
    <p>After removal of identifiers, your data may be used in future research studies or shared with other investigators without additional consent from you.</p>

    <h4>What are my rights as a research participant?</h4>
    <p>Your participation in this study is voluntary. You may skip any question you do not wish to answer, and you may withdraw at any time without penalty or loss of benefits. If you choose to withdraw, you may also request that your data not be used.</p>
    <p>If you are a University at Albany student or employee, choosing not to participate will not affect your grades, class standing, employment, or your relationship with the University.</p>

    <h4>Who can I contact if I have questions or concerns?</h4>
    <p><strong>For questions about this study:</strong><br>
    - Sijia (Estelle) Song – <a href="mailto:ssong@albany.edu">ssong@albany.edu</a><br>
    - Dr. Ronald Friedman (Faculty Advisor) – <a href="mailto:rfriedman@albany.edu">rfriedman@albany.edu</a></p>

    <p><strong>For questions about your rights as a research participant:</strong><br>
    Institutional Review Board<br>
    Office of Regulatory and Research Compliance<br>
    University at Albany<br>
    1400 Washington Ave, Biology 227<br>
    Albany, NY 12222<br>
    Phone: 1-866-857-5459<br>
    Email: <a href="mailto:rco@albany.edu">rco@albany.edu</a></p>

    <hr>
    <p><em>Consent Statement:</em> I have read (or been informed of) the information above. By clicking “I Agree” below, I consent to participate in this study.</p>
  </div>
`;

  const consentTrial = {
    type: jsPsychHtmlButtonResponse,
    stimulus: CONSENT_HTML,
    choices: ["Yes, I consent", "No, I do not consent"],
    on_finish: (data) => {
      data.phase = "consent";
      data.consent_choice = data.response === 0 ? "yes" : "no";
      CONSENT_GIVEN = (data.response === 0);
    }
  };

  /* ================================ Intro screens ================================ */
  const introScreens = [
    screenTrial(`
      <h2 class="center">Welcome to the study!</h2>
      <p style="text-align:left;">
        In this study, you will watch 36 short animated videos showing objects moving across the screen.
        The sound will also move between your left and right headphones as the object moves.
      </p>
      <p style="text-align:left;">
        To clearly hear the sound moving from side to side,
        <strong>please make sure you are wearing headphones in a quiet environment before continuing.</strong>
      </p>
      <p style="text-align:left;">You may need to scroll down to view the entire page.</p>
    `, "Next"),
    screenTrial(`
      <h3 class="center">What you'll do after each video</h3>
      <ol>
        <li><strong>Preference rating</strong> – “How much did you like the clip you just watched?”</li>
        <li><strong>Timing judgment</strong> – “To what extent did the visual and auditory motion begin at the same time?”<br>
          <small>This means: did the movement you <em>saw</em> and the movement you <em>heard</em> seem to start together, or did one begin slightly earlier?</small>
        </li>
        <li><strong>Memory test</strong> – Choose which of four options matches the clip you just watched. Options may differ in <em>direction</em> and/or <em>speed</em>.</li>
      </ol>
      <p>After all 36 trials, you’ll answer a few brief demographic questions.</p>
    `, "Next"),
    screenTrial(`
      <h3 class="center">Using the sliders</h3>
      <p>For the preference and timing ratings, you will use a slider from <strong>0 to 4</strong>.</p>
      <ul>
        <li>Move the slider to the number that best matches your judgment.</li>
        <li>If you want to select <strong>2 (Neutral)</strong>, click directly on the scale at 2.</li>
      </ul>
      <p>Let's start with a practice trial to learn the task.</p>
    `, "Begin practice")
  ];

  /* =============================== Practice timeline =============================== */
  const practiceTrials = [
    { scene: "practice1", direction: "LtoR", moa: "demo", stimulus: "videos/practice1_LtoR_demo.mp4" }
  ];
  const practiceTimeline = [
    viewClip(practiceTrials[0]),
    prefSlider(practiceTrials[0]),
    simultaneitySlider(practiceTrials[0]),
    memoryTrialPractice(practiceTrials[0])
  ];
  const practiceCompleteScreen = screenTrial(`
    <div class="center">
      <h3>Practice complete!</h3>
      <p>The main experiment will now begin.</p>
    </div>`, "Start main task");

  /* ================================== Main trials ================================== */
  const allTrials = [];
  scenes.forEach(scene=>{
    directions.forEach(dir=>{
      moas.forEach(moa=>{
        allTrials.push({ scene, direction: dir, moa, stimulus: `videos/${scene}_${dir}_${moa}.mp4` });
      });
    });
  });
function shuffleWithSceneGap(trials, maxTries = 5000){
  for (let tries = 0; tries < maxTries; tries++){
    const s = jsPsych.randomization.shuffle(trials);
    let ok = true;
    for (let i = 1; i < s.length; i++){
      if (s[i-1].scene === s[i].scene){ ok = false; break; }
    }
    if (ok) return s;
  }

  // Greedy fallback: interleave by scene
  const buckets = {};
  trials.forEach(t => { (buckets[t.scene] = buckets[t.scene] || []).push(t); });
  Object.values(buckets).forEach(arr => jsPsych.randomization.shuffle(arr));

  const sceneKeys = Object.keys(buckets);
  const result = [];
  let lastScene = null;

  while (result.length < trials.length){
    const choices = sceneKeys.filter(k => k !== lastScene && buckets[k].length > 0);
    const pickScene = choices.length
      ? choices[Math.floor(Math.random() * choices.length)]
      : sceneKeys.find(k => buckets[k].length > 0);
    result.push(buckets[pickScene].pop());
    lastScene = pickScene;
  }
  return result;
}

const constrained = shuffleWithSceneGap(allTrials);

const mainTimeline = [];
constrained.forEach(T => {
  mainTimeline.push(viewClip(T));
  mainTimeline.push(prefSlider(T));
  mainTimeline.push(simultaneitySlider(T));
  mainTimeline.push(memoryTrial(T));
});
  /* ============================ Final questions & Debrief ============================ */
  function oneTextQuestion({name, prompt, placeholder = "", required = true, button = "Continue"}) {
    return {
      type: jsPsychSurveyText,
      preamble: `<div class="center"><h2>Final Questions</h2></div>`,
      questions: [{ prompt: `<p style="font-weight:600;margin:0 0 8px">${prompt}</p>`, name, required, placeholder }],
      button_label: button,
      on_load: () => {
        const style = document.createElement("style");
        style.textContent = `
          .jspsych-survey-text .jspsych-survey-text-preamble { text-align:center; }
          .jspsych-survey-text-question { max-width:720px; margin:0 auto 18px; text-align:left; }
          .jspsych-survey-text-question input { width:100%; padding:10px; border-radius:8px; border:1px solid #ddd; font-size:16px; }
          .jspsych-btn { padding:10px 18px; border-radius:8px; }
        `;
        document.head.appendChild(style);
      }
    };
  }
  const q_age    = oneTextQuestion({ name:"age",            prompt:"1) Please enter your age.",            placeholder:"e.g., 26; 52" });
  const q_gender = oneTextQuestion({ name:"gender",         prompt:"2) Please enter your gender.",         placeholder:"e.g., woman / man / nonbinary / prefer to self-describe" });
  const q_race   = oneTextQuestion({ name:"race_ethnicity", prompt:"3) Please enter your race/ethnicity.", placeholder:"e.g., Asian; White; Black; Hispanic/Latino; Multiracial; …" });
  const q_hearing= oneTextQuestion({ name:"hearing",        prompt:"4) Do you have normal hearing?",       placeholder:"Yes / No / Unsure" });

const final_debrief = {
  type: jsPsychHtmlButtonResponse,
  stimulus: `
    <div style="max-width:820px;margin:0 auto;line-height:1.5;text-align:left;">
      <h2 class="center">Thank you for participating in this study!</h2>

      <p><strong>What was this study about?</strong><br>
      We’re studying how people remember short videos and how much they like them—especially when what you see and what you hear don’t line up perfectly. 
      In everyday life, sights and sounds usually start together (for example, you see a car move and hear it at the same time). 
      In our study, we sometimes made the sound’s movement start a little after the picture’s movement. 
      This timing gap is called motion onset asynchrony (MOA).</p>

      <p><strong>What did we test?</strong><br>
      We used three setups: no delay, a small delay, and a larger delay. 
      Our main idea is that a moderate delay might be “just right”—interesting enough to grab attention and help memory and liking, 
      but not so off that it feels distracting. We’ll also test whether liking helps explain memory—in other words, 
      whether clips you like more are also easier to remember when timing is a little off.</p>

      <p><strong>Why does this matter?</strong><br>
      Extended reality (XR) is used in training, education, games, and entertainment. Designers want experiences that people enjoy and also remember. 
      Those goals don’t always match: very immersive experiences can feel amazing yet sometimes make it harder to remember details, 
      while simpler setups can aid memory but feel less engaging. Our results can help find a better balance.</p>

      <p>If you would like to discuss the study further or are curious about this research, 
      please feel free to contact the researcher, <a href="mailto:ssong@albany.edu">Estelle Song</a>, 
      or the faculty advisor, <a href="mailto:rfriedman@albany.edu">Dr. Ronald Friedman</a>. 
      You may also contact either researcher if you would like your data withdrawn from the study. 
      If you choose to do so, you will still receive full credit for participation and will not be penalized in any way.</p>

      <p>If you experienced any discomfort during this study, or wish to discuss any other concerns, 
      you may contact the University Counseling Center at (518) 442-5800.</p>

      <p>Because this research is potentially important, we kindly ask that you please do not discuss the study with others before they participate. 
      Prior knowledge could affect their natural responses.</p>

      <p class="center"><strong>Thank you very much for your assistance with this project!</strong></p>
    </div>`,
  choices: ["Finish"]
};

const credit_section = {
  type: jsPsychHtmlButtonResponse,
  stimulus: `
    <div style="max-width:820px;margin:0 auto;line-height:1.5;text-align:left;">
      <h2 class="center">Research Credit Instructions</h2>
      <p>
        At the conclusion of this study, a <strong>unique completion code</strong> will be displayed on your screen. 
        Please record this code carefully and email it to 
        <a href="mailto:friedmanlab11@gmail.com">friedmanlab11@gmail.com</a> 
        to receive research credit.
      </p>
      <p><em>For confidentiality:</em> please include <strong>only</strong> the completion code in your email; 
      do not include your name, student ID, or any other personal information.</p>
    </div>`,
  choices: ["Finish"]
};
  /* ===================================== Run ===================================== */
jsPsych.run([
  consentTrial,           // consent first
  ...introScreens,
  ...practiceTimeline,
  practiceCompleteScreen,
  ...mainTimeline,
  q_age, q_gender, q_race, q_hearing,
  final_debrief,
  credit_section
]);



